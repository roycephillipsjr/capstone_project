{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier,\\\n",
    "                             AdaBoostClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('datasets/cleaned_lyrics_with_sentiment_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up my train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = songs['clean_lyrics']\n",
    "y = songs['american_songbook']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer With StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter=5000))\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2000, 3000, 4000, 5000],\n",
    "    'cvec__min_df': [1, 2, 3 , 4],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                  pipe_params,\n",
    "                  cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)...\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [1, 2, 3, 4],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745168599226976"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745098039215687"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.95,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "tfidf_pipe_params = {\n",
    "    'tfidf__max_features': [2000, 3000, 4000, 5000],\n",
    "    'tfidf__min_df': [1, 2, 3 , 4],\n",
    "    'tfidf__max_df': [.9, .95],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}\n",
    "\n",
    "gs_tfidf = GridSearchCV(tfidf_pipe,\n",
    "                        tfidf_pipe_params,\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'tfidf__max_df': [0.9, 0.95],\n",
       "                         'tfidf__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'tfidf__min_df': [1, 2, 3, 4],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
       "                         'tfidf__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7712914834066373"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803921568627451"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.9,\n",
       " 'tfidf__max_features': 3000,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('et', ExtraTreesClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "et_pipe_params = {\n",
    "    'tfidf__max_features': [3000],\n",
    "    'tfidf__min_df': [1],\n",
    "    'tfidf__max_df': [.9],\n",
    "    'tfidf__ngram_range': [(1,1)],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'et__n_estimators': [50, 100],\n",
    "    'et__max_features': [None, 'auto'],\n",
    "    'et__max_depth': [None, 2, 3, 4]\n",
    "}\n",
    "\n",
    "gs_et = GridSearchCV(et_pipe,\n",
    "                     et_pipe_params,\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'et__max_depth': [None, 2, 3, 4],\n",
       "                         'et__max_features': [None, 'auto'],\n",
       "                         'et__n_estimators': [50, 100], 'tfidf__max_df': [0.9],\n",
       "                         'tfidf__max_features': [3000], 'tfidf__min_df': [1],\n",
       "                         'tfidf__ngram_range': [(1, 1)],\n",
       "                         'tfidf__stop_words': [None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7826735972277754"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745098039215687"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'et__max_depth': None,\n",
       " 'et__max_features': 'auto',\n",
       " 'et__n_estimators': 100,\n",
       " 'tfidf__max_df': 0.9,\n",
       " 'tfidf__max_features': 3000,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_cv_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('et', ExtraTreesClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "et_cv_pipe_params = {\n",
    "    'cv__max_features': [2000],\n",
    "    'cv__min_df': [2],\n",
    "    'cv__max_df': [.95],\n",
    "    'cv__ngram_range': [(1,1)],\n",
    "    'cv__stop_words': [None],\n",
    "    'et__n_estimators': [50, 100],\n",
    "    'et__max_features': [None, 'auto'],\n",
    "    'et__max_depth': [None, 2, 3, 4]\n",
    "}\n",
    "\n",
    "gs_et_cv = GridSearchCV(et_cv_pipe,\n",
    "                        et_cv_pipe_params,\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cv',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)\\\\...\n",
       "                                                             warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cv__max_df': [0.95], 'cv__max_features': [2000],\n",
       "                         'cv__min_df': [2], 'cv__ngram_range': [(1, 1)],\n",
       "                         'cv__stop_words': [None],\n",
       "                         'et__max_depth': [None, 2, 3, 4],\n",
       "                         'et__max_features': [None, 'auto'],\n",
       "                         'et__n_estimators': [50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7746634679461548"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8186274509803921"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_df': 0.95,\n",
       " 'cv__max_features': 2000,\n",
       " 'cv__min_df': 2,\n",
       " 'cv__ngram_range': (1, 1),\n",
       " 'cv__stop_words': None,\n",
       " 'et__max_depth': None,\n",
       " 'et__max_features': 'auto',\n",
       " 'et__n_estimators': 100}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipe_params = {\n",
    "    'tfidf__max_features': [3000],\n",
    "    'tfidf__min_df': [1],\n",
    "    'tfidf__max_df': [.9],\n",
    "    'tfidf__ngram_range': [(1,1)],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'rf__n_estimators': [50, 100],\n",
    "    'rf__max_features': [None, 'auto'],\n",
    "    'rf__max_depth': [None, 2, 3, 4]\n",
    "}\n",
    "\n",
    "gs_rf = GridSearchCV(rf_pipe,\n",
    "                     rf_pipe_params,\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'rf__max_depth': [None, 2, 3, 4],\n",
       "                         'rf__max_features': [None, 'auto'],\n",
       "                         'rf__n_estimators': [50, 100], 'tfidf__max_df': [0.9],\n",
       "                         'tfidf__max_features': [3000], 'tfidf__min_df': [1],\n",
       "                         'tfidf__ngram_range': [(1, 1)],\n",
       "                         'tfidf__stop_words': [None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7516326802612288"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745098039215687"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': None,\n",
       " 'rf__max_features': 'auto',\n",
       " 'rf__n_estimators': 50,\n",
       " 'tfidf__max_df': 0.9,\n",
       " 'tfidf__max_features': 3000,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rf_cv_pipe_params = {\n",
    "    'cv__max_features': [2000],\n",
    "    'cv__min_df': [2],\n",
    "    'cv__max_df': [.95],\n",
    "    'cv__ngram_range': [(1,1)],\n",
    "    'cv__stop_words': [None],\n",
    "    'rf__n_estimators': [50, 100],\n",
    "    'rf__max_features': [None, 'auto'],\n",
    "    'rf__max_depth': [None, 2, 3, 4]\n",
    "}\n",
    "\n",
    "gs_rf_cv = GridSearchCV(rf_cv_pipe,\n",
    "                     rf_cv_pipe_params,\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cv',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)\\\\...\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cv__max_df': [0.95], 'cv__max_features': [2000],\n",
       "                         'cv__min_df': [2], 'cv__ngram_range': [(1, 1)],\n",
       "                         'cv__stop_words': [None],\n",
       "                         'rf__max_depth': [None, 2, 3, 4],\n",
       "                         'rf__max_features': [None, 'auto'],\n",
       "                         'rf__n_estimators': [50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7893909103025456"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7892156862745098"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_df': 0.95,\n",
       " 'cv__max_features': 2000,\n",
       " 'cv__min_df': 2,\n",
       " 'cv__ngram_range': (1, 1),\n",
       " 'cv__stop_words': None,\n",
       " 'rf__max_depth': None,\n",
       " 'rf__max_features': 'auto',\n",
       " 'rf__n_estimators': 100}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('SVC', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "SVC_pipe_params = {\n",
    "    'tfidf__max_features': [3000],\n",
    "    'tfidf__min_df': [1],\n",
    "    'tfidf__max_df': [.9],\n",
    "    'tfidf__ngram_range': [(1,1)],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'SVC__C': [1, .1, .01, .001],\n",
    "    'SVC__degree': [3, 4, 5],\n",
    "    'SVC__kernel': ['linear'],\n",
    "    'SVC__probability': [True]\n",
    "}\n",
    "\n",
    "gs_SVC = GridSearchCV(SVC_pipe,\n",
    "                     SVC_pipe_params,\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'SVC__C': [1, 0.1, 0.01, 0.001],\n",
       "                         'SVC__degree': [3, 4, 5], 'SVC__kernel': ['linear'],\n",
       "                         'SVC__probability': [True], 'tfidf__max_df': [0.9],\n",
       "                         'tfidf__max_features': [3000], 'tfidf__min_df': [1],\n",
       "                         'tfidf__ngram_range': [(1, 1)],\n",
       "                         'tfidf__stop_words': [None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7728775156604025"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVC__C': 1,\n",
       " 'SVC__degree': 3,\n",
       " 'SVC__kernel': 'linear',\n",
       " 'SVC__probability': True,\n",
       " 'tfidf__max_df': 0.9,\n",
       " 'tfidf__max_features': 3000,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_cv_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('SVC', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "SVC_cv_pipe_params = {\n",
    "    'cv__max_features': [2000],\n",
    "    'cv__min_df': [3],\n",
    "    'cv__max_df': [.95],\n",
    "    'cv__ngram_range': [(1,1)],\n",
    "    'cv__stop_words': [None],\n",
    "    'SVC__C': [1],\n",
    "    'SVC__degree': [3],\n",
    "    'SVC__kernel': ['linear']\n",
    "}\n",
    "\n",
    "gs_SVC_cv = GridSearchCV(SVC_cv_pipe,\n",
    "                     SVC_cv_pipe_params,\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cv',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)\\\\...\n",
       "                                            shrinking=True, tol=0.001,\n",
       "                                            verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'SVC__C': [1], 'SVC__degree': [3],\n",
       "                         'SVC__kernel': ['linear'], 'cv__max_df': [0.95],\n",
       "                         'cv__max_features': [2000], 'cv__min_df': [3],\n",
       "                         'cv__ngram_range': [(1, 1)],\n",
       "                         'cv__stop_words': [None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7271224843395974"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7450980392156863"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVC__C': 1,\n",
       " 'SVC__degree': 3,\n",
       " 'SVC__kernel': 'linear',\n",
       " 'cv__max_df': 0.95,\n",
       " 'cv__max_features': 2000,\n",
       " 'cv__min_df': 3,\n",
       " 'cv__ngram_range': (1, 1),\n",
       " 'cv__stop_words': None}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/questions/28384680/scikit-learns-pipeline-a-sparse-matrix-was-passed-but-dense-data-is-required\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   13.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cv',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u...\n",
       "                                        <__main__.DenseTransformer object at 0x1a11ee2ed0>),\n",
       "                                       ('gauss',\n",
       "                                        GaussianNB(priors=None,\n",
       "                                                   var_smoothing=1e-09))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'cv__max_df': [0.95],\n",
       "                         'cv__max_features': [2000, 3000, 4000],\n",
       "                         'cv__min_df': [1, 2, 3],\n",
       "                         'cv__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'cv__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('_', DenseTransformer()),\n",
    "    ('gauss', GaussianNB())\n",
    "])\n",
    "\n",
    "gauss_params = {\n",
    "    'cv__max_features': [2000, 3000, 4000],\n",
    "    'cv__min_df': [1, 2, 3],\n",
    "    'cv__max_df': [.95],\n",
    "    'cv__ngram_range': [(1,1), (1,2)],\n",
    "    'cv__stop_words': [None, 'english'],\n",
    "}\n",
    "\n",
    "gauss_gs = GridSearchCV(gauss_pipe, gauss_params, verbose=1, n_jobs=-1)\n",
    "\n",
    "gauss_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7500333200053312"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7598039215686274"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   15.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_...\n",
       "                                       ('gauss',\n",
       "                                        GaussianNB(priors=None,\n",
       "                                                   var_smoothing=1e-09))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'tfidf__max_df': [0.95],\n",
       "                         'tfidf__max_features': [2000, 3000, 4000],\n",
       "                         'tfidf__min_df': [1, 2, 3],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'tfidf__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_tfidf_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('_', DenseTransformer()),\n",
    "    ('gauss', GaussianNB())\n",
    "])\n",
    "\n",
    "gauss_tfidf_params = {\n",
    "    'tfidf__max_features': [2000, 3000, 4000],\n",
    "    'tfidf__min_df': [1, 2, 3],\n",
    "    'tfidf__max_df': [.95],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "}\n",
    "\n",
    "gauss_gs_tfidf = GridSearchCV(gauss_tfidf_pipe, gauss_tfidf_params, verbose=1, n_jobs=-1)\n",
    "\n",
    "gauss_gs_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7484073037451686"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_gs_tfidf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_gs_tfidf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA_cv_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('ADA', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "ADA_cv_pipe_params = {\n",
    "    'cv__max_features': [2000, 3000, 4000],\n",
    "    'cv__min_df': [1, 2, 3],\n",
    "    'cv__max_df': [.95],\n",
    "    'cv__ngram_range': [(1,1), (1,2)],\n",
    "    'cv__stop_words': [None, 'english'],\n",
    "    'ADA__n_estimators': [50, 100]\n",
    "}\n",
    "\n",
    "gs_ADA_cv = GridSearchCV(ADA_cv_pipe,\n",
    "                     ADA_cv_pipe_params,\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cv',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)\\\\...\n",
       "                                                           learning_rate=1.0,\n",
       "                                                           n_estimators=50,\n",
       "                                                           random_state=42))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'ADA__n_estimators': [50, 100], 'cv__max_df': [0.95],\n",
       "                         'cv__max_features': [2000, 3000, 4000],\n",
       "                         'cv__min_df': [1, 2, 3],\n",
       "                         'cv__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'cv__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ADA_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7452485672397708"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ADA_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6862745098039216"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ADA_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADA__n_estimators': 100,\n",
       " 'cv__max_df': 0.95,\n",
       " 'cv__max_features': 2000,\n",
       " 'cv__min_df': 1,\n",
       " 'cv__ngram_range': (1, 2),\n",
       " 'cv__stop_words': None}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ADA_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDFVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('ADA', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "ADA_pipe_params = {\n",
    "    'tfidf__max_features': [2000, 3000, 4000],\n",
    "    'tfidf__min_df': [1, 2, 3],\n",
    "    'tfidf__max_df': [.95],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'ADA__n_estimators': [50, 100]\n",
    "}\n",
    "\n",
    "gs_ADA = GridSearchCV(ADA_pipe,\n",
    "                     ADA_pipe_params,\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "                                                           n_estimators=50,\n",
       "                                                           random_state=42))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'ADA__n_estimators': [50, 100],\n",
       "                         'tfidf__max_df': [0.95],\n",
       "                         'tfidf__max_features': [2000, 3000, 4000],\n",
       "                         'tfidf__min_df': [1, 2, 3],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'tfidf__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ADA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7386378781820605"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ADA.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6764705882352942"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ADA.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cv_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "gb_cv_pipe_params = {\n",
    "    'cv__max_features': [2000, 3000, 4000],\n",
    "    'cv__min_df': [1, 2, 3],\n",
    "    'cv__max_df': [.95],\n",
    "    'cv__ngram_range': [(1,1), (1,2)],\n",
    "    'cv__stop_words': [None, 'english'],\n",
    "    'gb__n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "gs_gb_cv = GridSearchCV(gb_cv_pipe,\n",
    "                     gb_cv_pipe_params,\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cv',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)\\\\...\n",
       "                                                                   validation_fraction=0.1,\n",
       "                                                                   verbose=0,\n",
       "                                                                   warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cv__max_df': [0.95],\n",
       "                         'cv__max_features': [2000, 3000, 4000],\n",
       "                         'cv__min_df': [1, 2, 3],\n",
       "                         'cv__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'cv__stop_words': [None, 'english'],\n",
       "                         'gb__n_estimators': [50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768146074903372"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gb_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7254901960784313"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gb_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_df': 0.95,\n",
       " 'cv__max_features': 2000,\n",
       " 'cv__min_df': 3,\n",
       " 'cv__ngram_range': (1, 1),\n",
       " 'cv__stop_words': None,\n",
       " 'gb__n_estimators': 200}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gb_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe = Pipeline([\n",
    "    ('tfidf', TfiTfidfVectorizerctorizer()),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "gb_pipe_params = {\n",
    "    'tfidf__max_features': [2000, 3000, 4000],\n",
    "    'tfidf__min_df': [1, 2, 3],\n",
    "    'tfidf__max_df': [.95],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'gb__n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "gs_gb = GridSearchCV(gb_pipe,\n",
    "                     gb_pipe_params,\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "                                                                   warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'gb__n_estimators': [50, 100, 200],\n",
       "                         'tfidf__max_df': [0.95],\n",
       "                         'tfidf__max_features': [2000, 3000, 4000],\n",
       "                         'tfidf__min_df': [1, 2, 3],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'tfidf__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7550446488071438"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7156862745098039"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gb__n_estimators': 200,\n",
       " 'tfidf__max_df': 0.95,\n",
       " 'tfidf__max_features': 2000,\n",
       " 'tfidf__min_df': 3,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Scores combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Best Score, Logisitic Regression, CVEC: 0.7745168599226976\n",
      "Testing Score, Logisitic Regression, CVEC: 0.7745098039215687\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, Logisitic Regression, TFIDF: 0.7712914834066373\n",
      "Testing Score, Logisitic Regression, TFIDF: 0.803921568627451\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, Extra Tree Classifier, CVEC: 0.7746634679461548\n",
      "Testing Score, Extra Tree Classifier, CVEC: 0.8186274509803921\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, Extra Tree Classifier, TFIDF: 0.7826735972277754\n",
      "Testing Score, Extra Tree Classifier, TFIDF: 0.7745098039215687\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, Random Forest Classifier, CVEC: 0.7893909103025456\n",
      "Testing Score, Random Forest Classifier, CVEC: 0.7892156862745098\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, Random Forest Classifier, TFIDF: 0.7516326802612288\n",
      "Testing Score, Random Forest Classifier, TFIDF: 0.7745098039215687\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, SVC, CVEC: 0.7271224843395974\n",
      "Testing Score, SVC, CVEC: 0.7450980392156863\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, SVC, TFIDF: 0.7728775156604025\n",
      "Testing Score, Extra SVC, TFIDF: 0.8333333333333334\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, Gaussian, CVEC: 0.7500333200053312\n",
      "Testing Score, Gaussian, CVEC: 0.7598039215686274\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, Gaussian, TFIDF: 0.7484073037451686\n",
      "Testing Score, Gaussian, TFIDF: 0.7647058823529411\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, ADABoost, CVEC: 0.7452485672397708\n",
      "Testing Score, ADABoost, CVEC: 0.6862745098039216\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, ADABoost, TFIDF: 0.7386378781820605\n",
      "Testing Score, ADABoost, TFIDF: 0.6764705882352942\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, GradientBoost, CVEC: 0.768146074903372\n",
      "Testing Score, GradientBoost, CVEC: 0.7254901960784313\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training Best Score, GradientBoost, TFIDF: 0.7550446488071438\n",
      "Testing Score, GradientBoost, TFIDF: 0.7156862745098039\n"
     ]
    }
   ],
   "source": [
    "print('Training Best Score, Logisitic Regression, CVEC:', gs.best_score_)\n",
    "print('Testing Score, Logisitic Regression, CVEC:', gs.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, Logisitic Regression, TFIDF:', gs_tfidf.best_score_)\n",
    "print('Testing Score, Logisitic Regression, TFIDF:', gs_tfidf.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, Extra Tree Classifier, CVEC:', gs_et_cv.best_score_)\n",
    "print('Testing Score, Extra Tree Classifier, CVEC:', gs_et_cv.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, Extra Tree Classifier, TFIDF:', gs_et.best_score_)\n",
    "print('Testing Score, Extra Tree Classifier, TFIDF:', gs_et.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, Random Forest Classifier, CVEC:', gs_rf_cv.best_score_)\n",
    "print('Testing Score, Random Forest Classifier, CVEC:', gs_rf_cv.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, Random Forest Classifier, TFIDF:', gs_rf.best_score_)\n",
    "print('Testing Score, Random Forest Classifier, TFIDF:', gs_rf.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, SVC, CVEC:', gs_SVC_cv.best_score_)\n",
    "print('Testing Score, SVC, CVEC:', gs_SVC_cv.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, SVC, TFIDF:', gs_SVC.best_score_)\n",
    "print('Testing Score, Extra SVC, TFIDF:', gs_SVC.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, Gaussian, CVEC:', gauss_gs.best_score_)\n",
    "print('Testing Score, Gaussian, CVEC:', gauss_gs.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, Gaussian, TFIDF:', gauss_gs_tfidf.best_score_)\n",
    "print('Testing Score, Gaussian, TFIDF:', gauss_gs_tfidf.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, ADABoost, CVEC:', gs_ADA_cv.best_score_)\n",
    "print('Testing Score, ADABoost, CVEC:', gs_ADA_cv.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, ADABoost, TFIDF:', gs_ADA.best_score_)\n",
    "print('Testing Score, ADABoost, TFIDF:', gs_ADA.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, GradientBoost, CVEC:', gs_gb_cv.best_score_)\n",
    "print('Testing Score, GradientBoost, CVEC:', gs_gb_cv.score(X_test, y_test))\n",
    "print()\n",
    "print('='*100)\n",
    "print()\n",
    "print('Training Best Score, GradientBoost, TFIDF:', gs_gb.best_score_)\n",
    "print('Testing Score, GradientBoost, TFIDF:', gs_gb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model out of the models used seems to be the SVC using the TFIDFVectorizer\n",
    "\n",
    "**Training Score**, SVC, TFIDF: 0.7728775156604025\n",
    "<br>**Testing Score**, Extra SVC, TFIDF: 0.8333333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Best Score, SVC, TFIDF: 0.7728775156604025\n",
      "Testing Score, Extra SVC, TFIDF: 0.8333333333333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training Best Score, SVC, TFIDF:', gs_SVC.best_score_)\n",
    "print('Testing Score, Extra SVC, TFIDF:', gs_SVC.score(X_test, y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gs_SVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseSearchCV.score of GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "                                            verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'SVC__C': [1, 0.1, 0.01, 0.001],\n",
       "                         'SVC__degree': [3, 4, 5], 'SVC__kernel': ['linear'],\n",
       "                         'tfidf__max_df': [0.9], 'tfidf__max_features': [3000],\n",
       "                         'tfidf__min_df': [1], 'tfidf__ngram_range': [(1, 1)],\n",
       "                         'tfidf__stop_words': [None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_pipe_test = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('SVC', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "SVC_pipe_params_test = {\n",
    "    'SVC__C': [1],\n",
    "    'SVC__degree': [3],\n",
    "    'SVC__kernel': ['linear'],\n",
    "    'tfidf__max_df': [0.9],\n",
    "    'tfidf__max_features': [3000],\n",
    "    'tfidf__min_df': [1],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__stop_words': ['english']\n",
    "}\n",
    "\n",
    "gs_SVC_test = GridSearchCV(SVC_pipe_test,\n",
    "                     SVC_pipe_params_test,\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "                                            shrinking=True, tol=0.001,\n",
       "                                            verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'SVC__C': [1], 'SVC__degree': [3],\n",
       "                         'SVC__kernel': ['linear'], 'tfidf__max_df': [0.9],\n",
       "                         'tfidf__max_features': [3000], 'tfidf__min_df': [1],\n",
       "                         'tfidf__ngram_range': [(1, 1)],\n",
       "                         'tfidf__stop_words': ['english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC_test.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7597361055577768"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC_test.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7990196078431373"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SVC_test.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs['predictions_with_stopwords'] = gs_SVC_test.predict(songs['clean_lyrics_with_stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_stopwords = pd.DataFrame(gs_SVC_test.best_estimator_.steps[1][1].coef_.toarray(),\n",
    "             columns=gs_SVC_test.best_estimator_.steps[0][1].get_feature_names()).T.sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_stopwords = predictions_stopwords.rename(columns={0: 'coefs_with_stopword'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs_with_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <td>-1.962134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay</th>\n",
       "      <td>-1.275087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>-1.151061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>-1.140443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inside</th>\n",
       "      <td>-1.137415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belle</th>\n",
       "      <td>-1.128200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goodbye</th>\n",
       "      <td>-1.117720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wish</th>\n",
       "      <td>-1.084684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>-1.078975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>-1.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>-1.024638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <td>-1.012902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaston</th>\n",
       "      <td>-1.007493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>believing</th>\n",
       "      <td>-0.987285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>future</th>\n",
       "      <td>-0.985922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finally</th>\n",
       "      <td>-0.983777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beauty</th>\n",
       "      <td>-0.954688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother</th>\n",
       "      <td>-0.953933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dreaming</th>\n",
       "      <td>-0.939747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-0.932609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coefs_with_stopword\n",
       "song                 -1.962134\n",
       "stay                 -1.275087\n",
       "path                 -1.151061\n",
       "way                  -1.140443\n",
       "inside               -1.137415\n",
       "belle                -1.128200\n",
       "goodbye              -1.117720\n",
       "wish                 -1.084684\n",
       "world                -1.078975\n",
       "life                 -1.049800\n",
       "la                   -1.024638\n",
       "king                 -1.012902\n",
       "gaston               -1.007493\n",
       "believing            -0.987285\n",
       "future               -0.985922\n",
       "finally              -0.983777\n",
       "beauty               -0.954688\n",
       "mother               -0.953933\n",
       "dreaming             -0.939747\n",
       "max                  -0.932609"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_stopwords.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1248739 , -0.16165751,  0.18334382, ..., -0.13921812,\n",
       "        -0.53438041, -0.18614825]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_estimator_.steps[1][1].coef_.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(results.best_estimator_.steps[1][1].coef_.toarray(),\n",
    "             columns=results.best_estimator_.steps[0][1].get_feature_names()).T.sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.rename(columns={0: 'coefs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <td>-1.657070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>-1.557221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>-1.423257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>each</th>\n",
       "      <td>-1.274532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everything</th>\n",
       "      <td>-1.151166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>then</th>\n",
       "      <td>1.315654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>1.316975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.379970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>1.450071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby</th>\n",
       "      <td>1.612322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               coefs\n",
       "song       -1.657070\n",
       "this       -1.557221\n",
       "see        -1.423257\n",
       "each       -1.274532\n",
       "everything -1.151166\n",
       "...              ...\n",
       "then        1.315654\n",
       "love        1.316975\n",
       "man         1.379970\n",
       "was         1.450071\n",
       "baby        1.612322\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs_with_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <td>-1.962134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay</th>\n",
       "      <td>-1.275087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>-1.151061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>-1.140443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inside</th>\n",
       "      <td>-1.137415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>1.326396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby</th>\n",
       "      <td>1.400892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>1.409904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>1.521041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>1.550532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        coefs_with_stopword\n",
       "song              -1.962134\n",
       "stay              -1.275087\n",
       "path              -1.151061\n",
       "way               -1.140443\n",
       "inside            -1.137415\n",
       "...                     ...\n",
       "white              1.326396\n",
       "baby               1.400892\n",
       "easy               1.409904\n",
       "night              1.521041\n",
       "say                1.550532\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.concat([predictions, predictions_stopwords], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.to_csv('datasets/coefs_with_and_without_stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs['predictions'] = gs_SVC.predict(songs['clean_lyrics_with_stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.to_csv('datasets/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was learned from the pickle local lesson in week 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SVC.pkl', 'wb') as SCV_out:\n",
    "    pickle.dump(gs_SVC, SCV_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
